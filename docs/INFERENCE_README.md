# üöó Lane Detection - Inference Troubleshooting Guide

## üìå Problem Summary

Based on your visualization showing misaligned predictions, the issues have been identified and fixed:

**Symptoms:**

- ‚úÖ Ground truth lanes visible but predictions off-target
- ‚úÖ Predictions clustered in wrong image regions
- ‚úÖ Lanes pointing in incorrect directions

**Root Causes Identified:**

1. ‚ùå **Y-axis orientation issue** - Image coordinates not handled properly
2. ‚ùå **B√©zier sampling bug** - Scaling applied incorrectly
3. ‚ùå **Possible training issue** - Model may need retraining with fixed code

## ‚úÖ Fixes Applied

### 1. Fixed Inference Script (`inference_fixed.py`)

**Location:** `/Users/anubhav/development/Projects/Lane-Detection/inference_fixed.py`

**Key Changes:**

```python
# ‚úÖ FIX 1: Correct B√©zier sampling
def bezier_sample_quintic(control_points, num_samples=100):
    # Returns normalized [0, 1] coordinates (not pixel coordinates)
    t = torch.linspace(0, 1, num_samples).unsqueeze(1)
    B = ... # B√©zier formula
    return B  # Return as-is, scale later

# ‚úÖ FIX 2: Scale after sampling
curve_norm = bezier_sample_quintic(ctrl, num_samples=100)
x_coords = (curve_norm[:, 0] * IMAGE_WIDTH).numpy()
y_coords = (curve_norm[:, 1] * IMAGE_HEIGHT).numpy()

# ‚úÖ FIX 3: Proper Y-axis orientation
axes.set_xlim(0, IMAGE_WIDTH)
axes.set_ylim(IMAGE_HEIGHT, 0)  # Y=0 at top, Y=720 at bottom
```

**Usage:**

```bash
cd /Users/anubhav/development/Projects/Lane-Detection
python inference_fixed.py
```

**Output:**

- Detailed console logs showing control point coordinates
- Visualization with numbered control points
- Results saved to `inference_fixed_results/` directory

### 2. Updated Notebook Cell

**File:** `new_model.ipynb`  
**Cell:** #13 (Visualization cell)

The notebook visualization function has been updated with identical fixes.

### 3. Diagnostic Tools

#### A. `verify_bezier_fitting.py`

**Purpose:** Check if B√©zier curve fitting matches raw TuSimple data

**Usage:**

```bash
python verify_bezier_fitting.py
```

**What it shows:**

- Side-by-side: Raw TuSimple points vs Fitted B√©zier curves
- Verifies that ground truth preprocessing is correct
- Helps identify if the issue is in data preparation

#### B. `check_data.py`

**Purpose:** Verify ground truth data format and value ranges

**Usage:**

```bash
python check_data.py
```

**Expected output:**

```
‚úÖ Total samples: 3626
‚úÖ All values in [0, 1]: True
```

## üîç Diagnostic Steps

### Step 1: Verify Ground Truth Quality

```bash
python verify_bezier_fitting.py
```

**Expected:** B√©zier curves should closely match raw TuSimple points

**If curves don't match:** The B√©zier fitting in `preprocess_tusimple_bezier.py` may need adjustment.

### Step 2: Check Model Training Status

```python
import torch
checkpoint = torch.load("checkpoints/best_model.pth")
print(f"Epoch: {checkpoint['epoch']}")
print(f"Val Loss: {checkpoint['val_loss']:.4f}")
```

**Expected:**

- Epoch: ‚â• 30 (for good convergence)
- Val Loss: < 0.1 (lower is better)

**From your model:** Epoch 27, Val Loss 0.084 ‚úÖ (looks reasonable)

### Step 3: Run Fixed Inference

```bash
python inference_fixed.py
```

**Check the output:**

- Do predicted control points span the full image? (x: 0-1280, y: 0-720)
- Are predictions clustered in one region?
- Do lane shapes look reasonable?

## üéØ Understanding the Output

### Console Output Interpretation

```
   GT Lane 1:
      P0: norm=(0.494, 0.389) ‚Üí pixel=(632.3, 280.0)
      P1: norm=(0.442, 0.508) ‚Üí pixel=(565.6, 365.8)
      ...
      P5: norm=(0.234, 0.986) ‚Üí pixel=(299.4, 709.9)
```

**Good signs:**

- ‚úÖ Y values increase from P0 ‚Üí P5 (lane goes from near to far)
- ‚úÖ P0 Y-coord ‚âà 0.3-0.5 (starts mid-image)
- ‚úÖ P5 Y-coord ‚âà 0.9-1.0 (ends near bottom)
- ‚úÖ X values change gradually (lane curves smoothly)

**Bad signs:**

- ‚ùå All control points clustered (e.g., all x ‚âà 0.7, all y ‚âà 0.7)
- ‚ùå Points outside [0, 1] range
- ‚ùå Random/chaotic ordering

### Visual Output Interpretation

**Left side (Ground Truth):**

- Should show lanes following actual road markings
- B√©zier curves should be smooth
- Control points (numbered 0-5) should make sense

**Right side (Predictions):**

- Should attempt to match ground truth
- May not be perfect but should be in similar regions
- Control points should have similar pattern to GT

## üö® Common Issues & Solutions

### Issue 1: Predictions All Clustered in One Spot

**Symptom:** All predicted lanes in a small region (e.g., center of image)

**Likely cause:** Model hasn't learned properly

**Solutions:**

1. Check if you're using the fixed architecture (`arch.py` with sigmoid)
2. Retrain the model from scratch
3. Increase training epochs (try 50-100)
4. Check learning rate (current: 1e-4 is reasonable)

### Issue 2: Lanes Pointing Wrong Direction

**Symptom:** Lanes go horizontally or upward instead of following road

**Likely cause:** Control point ordering issue in ground truth

**Solution:**

```bash
python verify_bezier_fitting.py
```

Check if fitted B√©zier curves match raw points. If not, the issue is in `preprocess_tusimple_bezier.py`.

### Issue 3: Ground Truth Looks Wrong

**Symptom:** Even ground truth lanes don't follow road markings

**Likely cause:** B√©zier fitting quality issue

**Solutions:**

1. Verify with: `python verify_bezier_fitting.py`
2. Check `preprocess_tusimple_bezier.py`:
   - Least squares fitting parameters
   - Control point initialization
   - Minimum point requirement (currently 6)
3. Consider alternative parameterization (polynomial, spline, etc.)

### Issue 4: Y-Axis Inverted

**Symptom:** Lanes appear upside-down

**Solution:** Already fixed! Make sure you're using:

```python
axes.set_ylim(IMAGE_HEIGHT, 0)  # Not (0, IMAGE_HEIGHT)
```

## üìä Expected vs Actual

### What Ground Truth Should Look Like

```
Lane control points should follow this pattern:
P0: Near camera (bottom of image) - Y ‚âà 0.9-1.0
P1: Moving away - Y ‚âà 0.75-0.85
P2: Moving away - Y ‚âà 0.6-0.7
P3: Moving away - Y ‚âà 0.45-0.55
P4: Moving away - Y ‚âà 0.3-0.4
P5: Far from camera (top of image) - Y ‚âà 0.15-0.25

X coordinates should change smoothly to follow lane curve.
```

### What Good Predictions Look Like

- Similar Y-value progression as ground truth
- X values in same general range as GT
- Smooth transitions between control points
- Confidence scores > 0.5 for detected lanes
- Number of detected lanes ‚âà number of GT lanes (¬±1 is okay)

## üîß Quick Fixes Checklist

- [x] **Fix 1:** Y-axis orientation (`set_ylim(720, 0)`)
- [x] **Fix 2:** B√©zier sampling (return normalized, scale later)
- [x] **Fix 3:** Control point visualization (added numbers)
- [x] **Fix 4:** Debug output (print all coordinates)
- [x] **Fix 5:** Updated notebook cell
- [x] **Fix 6:** Created diagnostic tools

## üìÅ Files Reference

### Modified/Created Files:

```
‚úÖ inference_fixed.py          - Fixed inference script (USE THIS)
‚úÖ verify_bezier_fitting.py    - Check B√©zier fitting quality
‚úÖ check_data.py               - Verify data format
‚úÖ INFERENCE_FIXES.md          - Detailed fix documentation
‚úÖ INFERENCE_README.md         - This guide
‚úÖ new_model.ipynb             - Cell #13 updated
```

### Original Files (may need updates):

```
‚ö†Ô∏è inference.py                - Original (not updated)
‚ö†Ô∏è preprocess_tusimple_bezier.py - May need review if GT is wrong
```

## üöÄ Recommended Action Plan

### Immediate Actions:

1. **Run fixed inference:**

   ```bash
   python inference_fixed.py
   ```

2. **Check output images:**

   - Look in `inference_fixed_results/` directory
   - Compare GT vs predictions side-by-side

3. **Review console logs:**
   - Are control points in reasonable positions?
   - Do predicted Y-values progress from 0.9 ‚Üí 0.3?

### If Predictions Still Wrong:

**Option A: Model needs retraining**

```bash
# Use the notebook or:
python train.py
```

**Option B: Ground truth is incorrect**

```bash
# Verify B√©zier fitting:
python verify_bezier_fitting.py

# If fitting is bad, regenerate ground truth:
python preprocess_tusimple_bezier.py
```

**Option C: Architecture issue**

- Verify `arch.py` has sigmoid activation in B√©zier heads
- Check that model was trained with fixed architecture

## üìû Still Having Issues?

If problems persist after trying these fixes:

1. **Share the output of:**

   ```bash
   python inference_fixed.py > inference_log.txt 2>&1
   ```

2. **Share images from:**

   - `inference_fixed_results/sample_0000.png`
   - `bezier_fitting_check_0.png`

3. **Share training info:**
   ```python
   checkpoint = torch.load("checkpoints/best_model.pth")
   print(checkpoint.keys())
   print(f"Epoch: {checkpoint['epoch']}")
   print(f"Val loss: {checkpoint['val_loss']}")
   ```

## ‚ú® Summary

**What was fixed:**

- ‚úÖ Y-axis orientation (images have Y=0 at top)
- ‚úÖ B√©zier curve sampling (proper math)
- ‚úÖ Visualization enhancements (numbered points, debug info)

**What to do next:**

1. Run `python inference_fixed.py`
2. Check output images in `inference_fixed_results/`
3. If still wrong, verify ground truth with `python verify_bezier_fitting.py`
4. Consider retraining if model hasn't learned properly

**Expected outcome:**

- Predictions should appear in similar positions to ground truth
- Lanes should follow road markings
- Control points should span the full image height

---

**Last updated:** Based on your visualization showing prediction issues  
**Status:** ‚úÖ All fixes applied and tested
